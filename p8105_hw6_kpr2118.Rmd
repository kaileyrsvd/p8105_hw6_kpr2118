---
title: "Homework 6"
author: "Kailey Rishovd"
date: 12/09/2020
output: github_document
---

```{r setup, include= FALSE}
library(tidyverse)
library(viridis)
library(modelr)
library(p8105.datasets)

knitr::opts_chunk$set(
  echo = TRUE, 
  warning = FALSE,
  fig.width = 8,
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot.continuous.colour = "viridis", 
  ggplot.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

set.seed(1)
```

## Problem 1

```{r message=FALSE}
homicide_df = 
  read_csv("data/homicide-data.csv", na = c("", "NA", "Unknown")) %>%  
  mutate(
    city_state = str_c(city, state, sep = ", "), 
    victim_age = as.numeric(victim_age), 
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0, 
      disposition == "Open/No arrest"        ~ 0, 
      disposition == "Closed by arrest"      ~ 1)
  ) %>% 
  filter(
    victim_race %in% c("White", "Black"), 
    city_state != "Tulsa, AL") %>% 
  select(city_state, resolution, victim_age, victim_race, victim_sex)
```

Start with Baltimore, MD... 

```{r}
baltimore_df = 
  homicide_df %>% 
  filter(city_state == "Baltimore, MD")

glm(resolution ~ victim_age + victim_sex + victim_race, 
    data = baltimore_df, 
    family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(
    OR = exp(estimate), 
    CI_lower = exp(estimate - 1.96 * std.error), 
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(term, OR, starts_with("CI")) %>% 
  knitr::kable(digits = 3)
```

Try this across cities... 

```{r}
models_results_df = 
  homicide_df %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = 
      map(.x = data, ~glm(resolution ~ victim_age + victim_race + victim_sex, data = .x, family = binomial())), 
    results = map(models, broom::tidy)
  ) %>% 
  select(city_state, results) %>% 
  unnest(results) %>% 
  mutate(
    OR = exp(estimate), 
    CI_lower = exp(estimate - 1.96 * std.error), 
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(city_state, term, OR, starts_with("CI"))
```

Create a plot that shows the estimated ORs and CIs for each city... organized according to estimate OR

```{r}
models_results_df %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

This plot shows the odds ratios comparing male homicide victims to female homicide victims...Since most of the ORs are less than 1 (meaning that the outcome is less likely for males than the reference group "females"), we know that, relative to female homicides, male homicides are less likely to be resolved by arrest. Conversely, female homicides are more often resolved by arrest.

## Problem 2

Load and clean data

```{r message=FALSE}
birthweight_df = 
  read_csv("./data/birthweight.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    babysex = as.factor(babysex), 
    frace = as.factor(frace), 
    malform = as.factor(malform), 
    mrace = as.factor(mrace)
  )
```

Regression model for birthweight...

#### Modeling Process

Factors the underlay birthweight based on literature search:
`babysex` `bhead` `blength` `delwt` `fincome` `frace` `gaweeks` `momage` `mrace` `parity` `pnumlbw` `pnumgsa` `ppbmi` `ppwt` `smoken` 

Take out factors that are too alike and might cause multicolinearity:
`babysex` `bhead` `blength` `delwt` `fincome` `frace` `gaweeks` `momage` `mrace` `parity` `pnumlbw` `ppbmi` `ppwt` `smoken`

```{r}
factors_of_int_df = 
  lm(bwt ~  babysex + bhead + blength + delwt + fincome + frace + gaweeks + momage + mrace + parity + pnumlbw + ppbmi + ppwt + smoken, data = birthweight_df)
```

Look at results..  

```{r}
summary(factors_of_int_df)

broom::glance(factors_of_int_df)
```

Looking at the summary of the model p-values: `fincome`, `frace`, `momage`, `mrace` 3 and 4, and `ppwt` are not significant to the model. Further, `parity` is not highly significant to the model. I will keep `mrace` because one indicator variable was significant. Additionally, `pnumlbw` does not have enough data points. In my proposed model I will exclude all of the variables mentioned above, except `mrace.` 

R square is 71.8%

```{r}
proposed_model_df = 
  lm(bwt ~ bhead + blength + mrace + delwt + gaweeks + ppbmi + smoken, data = birthweight_df)

summary(proposed_model_df)

broom::glance(proposed_model_df)
```

I removed `babysex` because when running several linear models removing a variable at a time, removing this variable caused no change to the R square. 

R square is 71.7%

#### Residuals

Residuals against fitted values...

```{r}
resid_pred_p = 
  birthweight_df %>% 
    add_predictions(proposed_model_df) %>% 
    add_residuals(proposed_model_df) %>% 
    ggplot(aes(x = resid, y = pred)) +
    geom_point(alpha = .3)

resid_pred_p
```

Comparing model to two others... 

```{r}
main_effects_df = 
  lm(bwt ~ blength + gaweeks, data = birthweight_df)

broom::glance(main_effects_df)
```

```{r}
interactions_df = 
  lm(bwt ~ babysex * bhead *blength, data = birthweight_df)

broom::glance(interactions_df)
```

Using cross-validated prediction error: 

```{r}
cv_birthweight_df = 
  crossv_mc(birthweight_df, 100) %>% 
  mutate(
    train = map(train, as_tibble), 
    test = map(test, as_tibble)
  ) %>% 
  mutate(
    proposed_mod = map(.x = train, ~lm(bwt ~ bhead + blength + mrace + delwt + gaweeks + ppbmi + smoken, data = .x)), 
    maineff_mod = map(.x = train, ~lm(bwt ~ blength + gaweeks, data = .x)), 
    interactions_mod = map(.x = train, ~lm(bwt ~ babysex * bhead *blength, data = .x))
  ) %>%     
  mutate( 
    rmse_proposed = map2_dbl(.x = proposed_mod, .y = test, ~rmse(model = .x, data = .y)), 
    rmse_maineff = map2_dbl(.x = maineff_mod, .y = test, ~rmse(model = .x, data = .y)),
    rmse_interactions = map2_dbl(.x = interactions_mod, .y = test, ~rmse(model = .x, data = .y))
  )
```

What do these results say about model choice? 

```{r}
cv_birthweight_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(), 
    names_to = "model", 
    values_to = "rmse", 
    names_prefix = "rmse_"
  ) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin()
```

Compute averages... 

```{r}
cv_birthweight_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(), 
    names_to = "model", 
    values_to = "rmse", 
    names_prefix = "rmse_"
  ) %>%
  group_by(model) %>% 
  summarize(avg_rmse = mean(rmse))
```

Model choice? 

As we can see from the violin plot, *maineff* does not have great model fit because it will not predict birthweight sufficiently. 
The *interactions* and *proposed* models see improvement from *maineff*. 


In choosing a model, the model that will best predict birthweight, from the three models compared in this assignment, is the *proposed* model. This model has the lowest average rmse (275) and the smallest distribution of errors.

## Problem 3

Import data 

```{r message=FALSE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

Linear model to be focused on has `tmax` as the response and `tmin` as the predictor... 

```{r}
max_min_df = 
  lm(tmax ~ tmin, data = weather_df)

summary(max_min_df)
broom::glance(max_min_df)
```

Draw one bootstrap using a function...

```{r}
boot_max_min = function(df) { 
  
  sample_frac(df, replace = TRUE) %>% 
    arrange(tmin)
  
}
```

Check if the function is functioning... 

```{r}
boot_max_min(weather_df) %>% 
  ggplot(aes(x = tmin, y = tmax)) + 
  geom_point() + 
  geom_smooth(methog = "lm")

boot_max_min(weather_df) %>% 
  lm(tmax ~ tmin, data = .) %>% 
  broom::tidy()
```

Draw 5000 bootstrap samples and for each, produce estimates of interest (rsquaredhat and log of beta0hat*beta1hat) ...

```{r}
boot_straps_max_min = 
  tibble(
    strap_number = 1:5000, 
    strap_sample = rerun(5000, boot_max_min(weather_df))
  )

bs_max_min_results = 
  boot_straps_max_min %>% 
  mutate( 
    models = map(strap_sample, ~lm(tmax ~ tmin, data = .x)),
    get_rsqhat = map(models, broom::glance), 
    get_log = map(models, broom::tidy)
    ) %>% 
  unnest(get_rsqhat) %>% 
  select(strap_number, r.squared, get_log) %>% 
  unnest(get_log) %>% 
  select(strap_number, term, r.squared, estimate) %>% 
  pivot_wider(
    names_from = term,
    values_from = estimate
  ) %>% 
  rename(
    intercept = `(Intercept)`
  ) %>% 
  mutate(
    log_beta0_beta1 = log(intercept*tmin)
  ) %>% 
  select(strap_number, r.squared, log_beta0_beta1)
```

Plot the distribution of these estimates... 

```{r}
rsquarehat_p = 
  bs_max_min_results %>% 
    ggplot(aes(x = r.squared)) +
    geom_density() + 
    labs(
      title = "RSquared(Hat) Distribution"
    )

rsquarehat_p
```

For the rsquared(hat), the distribution peaks around 0.91. Additionally, it is between 0.87 and 0.94. The rsquared has a bell shape distribution which indicates normality. 

```{r}
log_p = 
  bs_max_min_results %>% 
  ggplot(aes(x = log_beta0_beta1)) +
  geom_density() + 
  labs(
    title = "Log(Beta0(hat) * Beta1(hat)) Distribution"
  )

log_p
```

For the log of beta0(hat)*beta1(hat), the distribution is also bell shaped but peaks at 2.02 and ranges from 1.925 and 2.10. This plot also has a normal looking distribution (but slightly less curved than the rsquared(hat) plot.) 

Using the estimates, identify the 2.5% and 97.5% quantities to provide a 95% confidence interval for rsquaredhat and log of beta0hat and beta1hat. 

```{r}
bs_max_min_results %>% 
  pivot_longer(
    r.squared:log_beta0_beta1,
    names_to = "estimate", 
    values_to = "est_value"
  ) %>% 
  group_by(strap_number, estimate) %>% 
  summarize(
    ci_lower = quantile(est_value, 0.025), 
    ci_upper = quantile(est_value, 0.975)
  ) 
```


