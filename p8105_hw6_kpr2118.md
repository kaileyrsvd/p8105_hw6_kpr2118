Homework 6
================
Kailey Rishovd
12/09/2020

## Problem 1

``` r
homicide_df = 
  read_csv("data/homicide-data.csv", na = c("", "NA", "Unknown")) %>%  
  mutate(
    city_state = str_c(city, state, sep = ", "), 
    victim_age = as.numeric(victim_age), 
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0, 
      disposition == "Open/No arrest"        ~ 0, 
      disposition == "Closed by arrest"      ~ 1)
  ) %>% 
  filter(
    victim_race %in% c("White", "Black"), 
    city_state != "Tulsa, AL") %>% 
  select(city_state, resolution, victim_age, victim_race, victim_sex)
```

Start with Baltimore, MD…

``` r
baltimore_df = 
  homicide_df %>% 
  filter(city_state == "Baltimore, MD")

glm(resolution ~ victim_age + victim_sex + victim_race, 
    data = baltimore_df, 
    family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(
    OR = exp(estimate), 
    CI_lower = exp(estimate - 1.96 * std.error), 
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(term, OR, starts_with("CI")) %>% 
  knitr::kable(digits = 3)
```

| term              |    OR | CI\_lower | CI\_upper |
| :---------------- | ----: | --------: | --------: |
| (Intercept)       | 1.363 |     0.975 |     1.907 |
| victim\_age       | 0.993 |     0.987 |     1.000 |
| victim\_sexMale   | 0.426 |     0.325 |     0.558 |
| victim\_raceWhite | 2.320 |     1.648 |     3.268 |

Try this across cities…

``` r
models_results_df = 
  homicide_df %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = 
      map(.x = data, ~glm(resolution ~ victim_age + victim_race + victim_sex, data = .x, family = binomial())), 
    results = map(models, broom::tidy)
  ) %>% 
  select(city_state, results) %>% 
  unnest(results) %>% 
  mutate(
    OR = exp(estimate), 
    CI_lower = exp(estimate - 1.96 * std.error), 
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(city_state, term, OR, starts_with("CI"))
```

Create a plot that shows the estimated ORs and CIs for each city…
organized according to estimate OR

``` r
models_results_df %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

<img src="p8105_hw6_kpr2118_files/figure-gfm/unnamed-chunk-4-1.png" width="90%" />

Comment on plot HERE Plot shows the ORs comparing male homicide victims
to female homicide victims… relative to homicides more or less likely to
be resolved by arrest Less often that male homicide victim cases are
resolved by arrest

## Problem 2

Load and clean data

``` r
birthweight_df = 
  read_csv("./data/birthweight.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    babysex = as.factor(babysex), 
    frace = as.factor(frace), 
    malform = as.factor(malform), 
    mrace = as.factor(mrace)
  )
```

Regression model for birthweight…

#### Modeling Process

Factors the underlay birthweight based on literature search: `babysex`
`bhead` `blength` `delwt` `fincome` `frace` `gaweeks` `momage` `mrace`
`parity` `pnumlbw` `pnumgsa` `ppbmi` `ppwt` `smoken`

Take out factors that are too alike and might cause multicolinearity:
`babysex` `bhead` `blength` `delwt` `fincome` `frace` `gaweeks` `momage`
`mrace` `parity` `pnumlbw` `ppbmi` `ppwt` `smoken`

``` r
factors_of_int_df = 
  lm(bwt ~  babysex + bhead + blength + delwt + fincome + frace + gaweeks + momage + mrace + parity + pnumlbw + ppbmi + ppwt + smoken, data = birthweight_df)
```

Look at results..

``` r
summary(factors_of_int_df)
```

    ## 
    ## Call:
    ## lm(formula = bwt ~ babysex + bhead + blength + delwt + fincome + 
    ##     frace + gaweeks + momage + mrace + parity + pnumlbw + ppbmi + 
    ##     ppwt + smoken, data = birthweight_df)
    ## 
    ## Residuals:
    ##      Min       1Q   Median       3Q      Max 
    ## -1093.35  -184.72    -4.27   173.72  2355.26 
    ## 
    ## Coefficients: (1 not defined because of singularities)
    ##               Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept) -5691.3761   103.0812 -55.213  < 2e-16 ***
    ## babysex2       28.6925     8.4637   3.390 0.000705 ***
    ## bhead         130.7985     3.4500  37.912  < 2e-16 ***
    ## blength        75.0335     2.0205  37.135  < 2e-16 ***
    ## delwt           4.1247     0.3942  10.464  < 2e-16 ***
    ## fincome         0.3067     0.1791   1.712 0.087000 .  
    ## frace2         13.3553    46.1297   0.290 0.772200    
    ## frace3         19.7755    69.2842   0.285 0.775331    
    ## frace4        -49.2524    44.6486  -1.103 0.270040    
    ## frace8          4.1866    74.0602   0.057 0.954922    
    ## gaweeks        11.5305     1.4651   7.870 4.44e-15 ***
    ## momage          0.4997     1.1996   0.417 0.677036    
    ## mrace2       -151.1299    46.0362  -3.283 0.001036 ** 
    ## mrace3        -94.7768    71.8744  -1.319 0.187358    
    ## mrace4        -56.5599    45.1181  -1.254 0.210057    
    ## parity         94.5298    40.4697   2.336 0.019546 *  
    ## pnumlbw             NA         NA      NA       NA    
    ## ppbmi          -9.1544     2.5794  -3.549 0.000391 ***
    ## ppwt           -1.1065     0.5726  -1.932 0.053391 .  
    ## smoken         -4.8710     0.5867  -8.302  < 2e-16 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 272.5 on 4323 degrees of freedom
    ## Multiple R-squared:  0.7182, Adjusted R-squared:  0.717 
    ## F-statistic:   612 on 18 and 4323 DF,  p-value: < 2.2e-16

``` r
broom::glance(factors_of_int_df)
```

    ## # A tibble: 1 x 12
    ##   r.squared adj.r.squared sigma statistic p.value    df  logLik    AIC    BIC
    ##       <dbl>         <dbl> <dbl>     <dbl>   <dbl> <dbl>   <dbl>  <dbl>  <dbl>
    ## 1     0.718         0.717  272.      612.       0    18 -30499. 61038. 61166.
    ## # ... with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>

Looking at the summary of the model p-values: `fincome`, `frace`,
`momage`, `mrace` 3 and 4, and `ppwt` are not significant to the model.
Further, `parity` is not highly significant to the model. I will keep
`mrace` because one indicator variable was significant. Additionally,
`pnumlbw` does not have enough data points. In my proposed model I will
exclude all of the variables mentioned above, except `mrace.`

R square is 71.8%

``` r
proposed_model_df = 
  lm(bwt ~ bhead + blength + mrace + delwt + gaweeks + ppbmi + smoken, data = birthweight_df)

summary(proposed_model_df)
```

    ## 
    ## Call:
    ## lm(formula = bwt ~ bhead + blength + mrace + delwt + gaweeks + 
    ##     ppbmi + smoken, data = birthweight_df)
    ## 
    ## Residuals:
    ##      Min       1Q   Median       3Q      Max 
    ## -1121.74  -179.62    -3.01   172.58  2314.76 
    ## 
    ## Coefficients:
    ##               Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept) -5598.8294    99.5597 -56.236  < 2e-16 ***
    ## bhead         129.6223     3.4085  38.030  < 2e-16 ***
    ## blength        74.5772     2.0210  36.901  < 2e-16 ***
    ## mrace2       -144.9746     9.2209 -15.722  < 2e-16 ***
    ## mrace3        -80.7445    42.3494  -1.907   0.0566 .  
    ## mrace4       -100.3123    18.8795  -5.313 1.13e-07 ***
    ## delwt           3.6505     0.2846  12.826  < 2e-16 ***
    ## gaweeks        12.0251     1.4507   8.289  < 2e-16 ***
    ## ppbmi         -12.6864     1.9191  -6.610 4.30e-11 ***
    ## smoken         -4.9783     0.5861  -8.495  < 2e-16 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 273 on 4332 degrees of freedom
    ## Multiple R-squared:  0.7165, Adjusted R-squared:  0.7159 
    ## F-statistic:  1217 on 9 and 4332 DF,  p-value: < 2.2e-16

``` r
broom::glance(proposed_model_df)
```

    ## # A tibble: 1 x 12
    ##   r.squared adj.r.squared sigma statistic p.value    df  logLik    AIC    BIC
    ##       <dbl>         <dbl> <dbl>     <dbl>   <dbl> <dbl>   <dbl>  <dbl>  <dbl>
    ## 1     0.717         0.716  273.     1217.       0     9 -30512. 61046. 61116.
    ## # ... with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>

I removed `babysex` becuase when removing, it caused no change to the R
square.

R square is 71.7%

#### Residuals

Residuals against fitted values…

``` r
resid_pred_p = 
  birthweight_df %>% 
    add_predictions(proposed_model_df) %>% 
    add_residuals(proposed_model_df) %>% 
    ggplot(aes(x = resid, y = pred)) +
    geom_point(alpha = .3)

resid_pred_p
```

<img src="p8105_hw6_kpr2118_files/figure-gfm/unnamed-chunk-9-1.png" width="90%" />

Comparing model to two others…

``` r
main_effects_df = 
  lm(bwt ~ blength + gaweeks, data = birthweight_df)

broom::glance(main_effects_df)
```

    ## # A tibble: 1 x 12
    ##   r.squared adj.r.squared sigma statistic p.value    df  logLik    AIC    BIC
    ##       <dbl>         <dbl> <dbl>     <dbl>   <dbl> <dbl>   <dbl>  <dbl>  <dbl>
    ## 1     0.577         0.577  333.     2958.       0     2 -31381. 62771. 62796.
    ## # ... with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>

``` r
interactions_df = 
  lm(bwt ~ babysex * bhead *blength, data = birthweight_df)

broom::glance(interactions_df)
```

    ## # A tibble: 1 x 12
    ##   r.squared adj.r.squared sigma statistic p.value    df  logLik    AIC    BIC
    ##       <dbl>         <dbl> <dbl>     <dbl>   <dbl> <dbl>   <dbl>  <dbl>  <dbl>
    ## 1     0.685         0.684  288.     1346.       0     7 -30742. 61501. 61559.
    ## # ... with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>

Cross-validated prediction error:

``` r
cv_birthweight_df = 
  crossv_mc(birthweight_df, 100) %>% 
  mutate(
    train = map(train, as_tibble), 
    test = map(test, as_tibble)
  ) %>% 
  mutate(
    proposed_mod = map(.x = train, ~lm(bwt ~ bhead + blength + mrace + delwt + gaweeks + ppbmi + smoken, data = .x)), 
    maineff_mod = map(.x = train, ~lm(bwt ~ blength + gaweeks, data = .x)), 
    interactions_mod = map(.x = train, ~lm(bwt ~ babysex * bhead *blength, data = .x))
  ) %>%     
  mutate( 
    rmse_proposed = map2_dbl(.x = proposed_mod, .y = test, ~rmse(model = .x, data = .y)), 
    rmse_maineff = map2_dbl(.x = maineff_mod, .y = test, ~rmse(model = .x, data = .y)),
    rmse_interactions = map2_dbl(.x = interactions_mod, .y = test, ~rmse(model = .x, data = .y))
  )
```

What do these results say about model choice?

``` r
cv_birthweight_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(), 
    names_to = "model", 
    values_to = "rmse", 
    names_prefix = "rmse_"
  ) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin()
```

<img src="p8105_hw6_kpr2118_files/figure-gfm/unnamed-chunk-13-1.png" width="90%" />

Compute averages…

``` r
cv_birthweight_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(), 
    names_to = "model", 
    values_to = "rmse", 
    names_prefix = "rmse_"
  ) %>%
  group_by(model) %>% 
  summarize(avg_rmse = mean(rmse))
```

    ## `summarise()` ungrouping output (override with `.groups` argument)

    ## # A tibble: 3 x 2
    ##   model        avg_rmse
    ##   <chr>           <dbl>
    ## 1 interactions     289.
    ## 2 maineff          332.
    ## 3 proposed         273.

Model choice?

As we can see from the violin plot, *maineff* does not have great model
fit because it will not predict birthweight sufficiently. The
*interactions* and *proposed* models see improvement from *maineff*.

In choosing a model, the model that will best predict birthweight, from
the three models compared in this assignment, is the *proposed* model.
This model has the lowest average rmse (275) and the smallest
distribution of errors.

## Problem 3

Import data

``` r
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```
